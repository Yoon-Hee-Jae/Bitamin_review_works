{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["## 기본 Library 선언"],"metadata":{"id":"w3oblCTtv0Lr"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import tensorflow as tf\n","\n","tf.random.set_seed(777)  "],"metadata":{"id":"pGzFSu6sv2MD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## AND, OR, XOR 데이터 구현"],"metadata":{"id":"jUrGK_QL9iCz"}},{"cell_type":"code","source":["T = 1.0\n","F = 0.0\n","bias = 1.0"],"metadata":{"id":"fuBTYKuPv5XG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_AND_data():\n","    X = [\n","    [F, F, bias],\n","    [F, T, bias],\n","    [T, F, bias],\n","    [T, T, bias]\n","    ]\n","    \n","    Y = [\n","        [F],\n","        [F],\n","        [F],\n","        [T]\n","    ]\n","    \n","    return X, Y"],"metadata":{"id":"ZT7fDlOVv5VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_OR_data():\n","    X = [\n","    [F, F, bias],\n","    [F, T, bias],\n","    [T, F, bias],\n","    [T, T, bias]\n","    ]\n","    \n","    Y = [\n","        [F],\n","        [T],\n","        [T],\n","        [T]\n","    ]\n","    \n","    return X, Y"],"metadata":{"id":"PjM-LE_Wv5Sa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_XOR_data():\n","    X = [\n","    [F, F, bias],\n","    [F, T, bias],\n","    [T, F, bias],\n","    [T, T, bias]\n","    ]\n","    \n","    Y = [\n","        [F],\n","        [T],\n","        [T],\n","        [F]\n","    ]\n","    \n","    return X, Y"],"metadata":{"id":"YHzv37-_v5Pj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 시각화\n","\n","* X가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 Y 0과 1로 구분하는 예제입니다\n","* 붉은색과 푸른색으로 0과 1을 표시해 보도록 하겠습니다."],"metadata":{"id":"XPEcsLFf94Bl"}},{"cell_type":"markdown","source":["### AND"],"metadata":{"id":"vToob-Rt7RfX"}},{"cell_type":"code","source":["X, Y = get_AND_data()\n","\n","plt.scatter(X[0][0],X[0][1], c='blue' , marker='^')\n","plt.scatter(X[3][0],X[3][1], c='red' , marker='^')\n","plt.scatter(X[1][0],X[1][1], c='blue' , marker='^')\n","plt.scatter(X[2][0],X[2][1], c='blue' , marker='^')\n","\n","plt.xlabel(\"x1\")\n","plt.ylabel(\"x2\")\n","plt.show()"],"metadata":{"id":"zk2zg_uuxnz2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### OR"],"metadata":{"id":"zPDCEh177Uir"}},{"cell_type":"code","source":["X, Y = get_OR_data()\n","\n","plt.scatter(X[0][0],X[0][1], c='blue' , marker='^')\n","plt.scatter(X[3][0],X[3][1], c='red' , marker='^')\n","plt.scatter(X[1][0],X[1][1], c='red' , marker='^')\n","plt.scatter(X[2][0],X[2][1], c='red' , marker='^')\n","\n","plt.xlabel(\"x1\")\n","plt.ylabel(\"x2\")\n","plt.show()"],"metadata":{"id":"URiRRHm0v5M8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### XOR"],"metadata":{"id":"tq9C0A6n7Y6t"}},{"cell_type":"code","source":["X, Y = get_XOR_data()\n","\n","plt.scatter(X[0][0],X[0][1], c='blue' , marker='^')\n","plt.scatter(X[3][0],X[3][1], c='blue' , marker='^')\n","plt.scatter(X[1][0],X[1][1], c='red' , marker='^')\n","plt.scatter(X[2][0],X[2][1], c='red' , marker='^')\n","\n","plt.xlabel(\"x1\")\n","plt.ylabel(\"x2\")\n","plt.show()"],"metadata":{"id":"IPFhRN_Hv5Kr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 생성 후 평가"],"metadata":{"id":"HdtaLq0k-He5"}},{"cell_type":"markdown","source":["### AND, OR\n","\n","AND, OR 데이터를 분류하는 단일 신경망을 만들겠습니다.\n","\n","1. 출력 뉴런 수(units)가 1, 입력층의 뉴런 수(input_dim)가 3, 활성화 함수가 sigmoid인 dense를 하나 추가하세요.\n","\n","2. 이진 분류일 때 사용하는 loss를 입력하여 compile을 완성해주세요.\n","\n","**실행하면 시간이 꽤 걸리니 나중에 해보시길 추천드립니다!**"],"metadata":{"id":"nSlSNo_Z-lw3"}},{"cell_type":"code","source":["X, Y = get_AND_data()\n","#X, Y = get_OR_data()\n","\n","tf.model = tf.keras.Sequential()\n","'''1'''\n","tf.model.compile('''2''', optimizer=tf.optimizers.SGD(lr=0.01),  metrics=['accuracy'])\n","tf.model.summary()\n","\n","history = tf.model.fit(X, Y, epochs=5000)\n","\n","predictions = tf.model.predict(X)\n","print('Prediction: \\n', predictions)\n","\n","score = tf.model.evaluate(X, Y)\n","print('Accuracy: ', score[1])"],"metadata":{"id":"dkXzCKe07dIH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### XOR\n","\n","XOR 데이터를 분류하는 단일 신경망을 만들겠습니다.\n","\n","신경망 모델은 위와 동일하게 만들겠습니다.\n","\n","**실행하면 시간이 꽤 걸리니 나중에 해보시길 추천드립니다!**"],"metadata":{"id":"Pp7rs8Wg-oRT"}},{"cell_type":"code","source":["X, Y = get_XOR_data()\n","\n","'''\n","신경망 모델을 작성해 주세요.\n","'''\n","tf.model.summary()\n","\n","history = tf.model.fit(X, Y, epochs=5000)\n","\n","predictions = tf.model.predict(X)\n","print('Prediction: \\n', predictions)\n","\n","score = tf.model.evaluate(X, Y)\n","print('Accuracy: ', score[1])"],"metadata":{"id":"owmchtnX7dDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["분류가 잘 되지 않은 것을 확인하였습니다."],"metadata":{"id":"2mDGEi8XA7gF"}},{"cell_type":"markdown","source":["### XOR with MLP\n","\n","신경망 층을 늘려 XOR 데이터를 분류하겠습니다. \n","\n","1. 첫 번째 dense는 출력 뉴런 수(units)가 10, 입력층의 뉴런 수(input_dim)가 3, 활성화 함수가 sigmoid로 만들겠습니다. \n","2. 뉴런 수(units)가 10, 활성화 함수가 sigmoid인 dense를 3개 추가해주세요.\n","3. 마지막 dense는 출력 뉴런 수가 1, 활성화 함수 sigmoid로 만들어주세요."],"metadata":{"id":"Nev8fi7i-rVH"}},{"cell_type":"code","source":["tf.model = tf.keras.Sequential()\n","'''\n","신경망 모델을 작성해 주세요.\n","'''\n","tf.model.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(lr=0.1), metrics=['accuracy'])\n","tf.model.summary()\n","\n","history = tf.model.fit(X, Y, epochs=5000)\n","\n","predictions = tf.model.predict(X)\n","print('Prediction: \\n', predictions)\n","\n","score = tf.model.evaluate(X, Y)\n","print('Accuracy: ', score[1])"],"metadata":{"id":"yhzChJix7jbz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# pytorch 이용해서 MLP 구현"],"metadata":{"id":"jimKKsn6fYNR"}},{"cell_type":"markdown","source":["pytorch를 이용해서 MLP를 구현하고, Fashion-MNIST 데이터셋을 분류해보겠습니다!<br>\n","기본 실습코드는 2개의 perceptron을 이용한 MLP 모델이 구현되어 있습니다. <br>\n","<br>\n","하이퍼 파라미터와 레이어 개수 등을 조절하면서 정확도를 확인해보세요!!"],"metadata":{"id":"ubGWHufBfkZd"}},{"cell_type":"markdown","source":["## 1. 필요한 라이브러리 import"],"metadata":{"id":"cjIqFdc-g6Qe"}},{"cell_type":"code","source":["import torch\n","import os\n","import numpy as np\n","import time\n","import random\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import FashionMNIST\n","%matplotlib inline"],"metadata":{"id":"eRiXvRxHg5M8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["랜덤 시드 지정 및 GPU 설정"],"metadata":{"id":"HulOCcmehAAv"}},{"cell_type":"code","source":["RANDOM_SEED = 123\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"48EkSmmpfkCN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 데이터 셋 설명"],"metadata":{"id":"8p1_nKl4hNLL"}},{"cell_type":"markdown","source":["Fashion-MNIST는 10개의 클래스로 이루어진 데이터셋입니다. <br>\n","28x28의 흑백 이미지로 60,000개의 학습 이미지와 10,000개의 테스트 이미지를 갖고 있으며, label은 다음과 같습니다. <br>\n","(https://github.com/zalandoresearch/fashion-mnist) <br>\n","<br>\n","\n","| Label | Description |\n","| --- | --- |\n","| 0 | T-shirt/top |\n","| 1 | Trouser |\n","| 2 | Pullover |\n","| 3 | Dress |\n","| 4 | Coat |\n","| 5 | Sandal |\n","| 6 | Shirt |\n","| 7 | Sneaker |\n","| 8 | Bag |\n","| 9 | Ankle boot |\n","\n","\n"],"metadata":{"id":"UXvV6C4oh1om"}},{"cell_type":"markdown","source":["## 3. Dataset Loader"],"metadata":{"id":"c7_mUph6jVtd"}},{"cell_type":"markdown","source":["이미지 데이터 전처리를 위해서 transforms을 정의하고, DataLoader를 통해서 데이터를 불러오겠습니다. <br>\n","DataLoader는 학습 시 Dataset에 쉬운 접근을 위해, 데이터셋을 iterable한 형태로 만들어줍니다.   "],"metadata":{"id":"6PO3YibMjZYR"}},{"cell_type":"markdown","source":["Train transform"],"metadata":{"id":"4mowsqiElurc"}},{"cell_type":"code","source":["custom_train_transform = transforms.Compose([  \n","                                             transforms.ToTensor(), # 이미지나 ndarray를 tensor 형태로 변경 \n","                                             transforms.Normalize(mean=(0.5,), std=(0.5,)) # 정규화 \n","])"],"metadata":{"id":"Z4zOR_RrjZAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test transform"],"metadata":{"id":"58BjWU2Nl1pb"}},{"cell_type":"code","source":["custom_test_transform = transforms.Compose([\n","                                             transforms.ToTensor(),\n","                                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n","])"],"metadata":{"id":"1hQ1vfsehu2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDgqxOaEeA5d"},"outputs":[],"source":["# Batch size = 1 이면 online 학습 \n","# Batch size = 60000 이면 full batch 학습 \n","# 1 < Batch size < 60000 이면 mini batch 학습   \n","BATCH_SIZE = ''' BATCH_SIZE를 지정해주세요. '''"]},{"cell_type":"markdown","source":["전처리하고, 데이터 로딩"],"metadata":{"id":"lUZBKJe9mf_k"}},{"cell_type":"code","source":["train_dataset = FashionMNIST(\".\", train=True, download=True, transform=custom_train_transform)\n","\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True,\n","                          drop_last=True,\n","                          num_workers=2)\n","\n","\n","test_dataset = FashionMNIST(\".\", train=False, download=True, transform=custom_test_transform)\n","\n","test_loader = DataLoader(dataset=test_dataset,\n","                         batch_size=BATCH_SIZE,\n","                         shuffle=False,\n","                         num_workers=2)"],"metadata":{"id":"_NkkppThmesQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 셋이 잘 로딩되었는지 확인"],"metadata":{"id":"8M_buOsImZ2e"}},{"cell_type":"code","source":["num_epochs = 1\n","for epoch in range(num_epochs):\n","\n","    for batch_idx, (x, y) in enumerate(train_loader):\n","        \n","        print('Epoch:', epoch+1, end='')\n","        print(' | Batch index:', batch_idx, end='')\n","        print(' | Batch size:', y.size()[0])\n","        \n","        x = x.to(DEVICE)\n","        y = y.to(DEVICE)\n","        print(f'Image data shape: \\t {x.shape}')\n","        print(f'Label data shape: \\t {y.shape}')\n","        print(y)\n","        break"],"metadata":{"id":"rGZpHn-tmnOb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. MLP 모델 정의 "],"metadata":{"id":"Xv6vaBf7msgq"}},{"cell_type":"markdown","source":["MLP 모델을 정의하겠습니다. <br>\n","기본적으로 작성되어 있는 코드는 1개의 은닉층을 갖는 2-layer perceptron 입니다.<br>\n","<br>\n","코드를 수정해서 hidden layer를 추가해주세요!  "],"metadata":{"id":"wixyuHIrmwna"}},{"cell_type":"code","source":["class MLP(torch.nn.Module):\n","\n","    def __init__(self, num_features, num_hidden_1, num_classes):\n","        super(MLP, self).__init__()\n","        \n","        self.num_classes = num_classes # 10 \n","        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n","        \n","        '''\n","        hidden layer를 추가해주세요.(추가한 layer에 맞춰서 생성자 메서드(__init__)의 파라미터도 바꿔주셔야 합니다!)\n","        '''\n","        \n","        self.linear_out = torch.nn.Linear(''' layer에 맞춰서 작성해주세요. ''', num_classes)\n","        \n","        # Multi-class classification 문제를 풀기 위해 Softmax 함수를 사용\n","        self.softmax = torch.nn.Softmax(dim=-1)\n","        \n","    def forward(self, x):\n","        \n","        ### activation 함수 변경 가능\n","        ### 레이어간의 연결 추가, 변경\n","        out = self.linear_1(x)\n","        out = torch.sigmoid(out)\n","    \n","        '''\n","        추가한 layer에 맞춰서 layer 간의 연결 및 활성 함수 코드를 작성해주세요. \n","        '''\n","\n","        logits = self.linear_out(out)\n","        \n","        # Multi-class classification 문제를 풀기 위해 Softmax 함수를 사용합니다.\n","        # 다만, 이후 사용할 F.cross_entropy() 함수 내부에 softmax가 이미 구현되어 있기 때문에\n","        # Loss function 계산 시에는 self.softmax()를 통과하기 전의 logits 값을 이용하게 됩니다.\n","        probas = self.softmax(logits)\n","        return logits, probas\n","\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"],"metadata":{"id":"UtLPLp5Xmw2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Training"],"metadata":{"id":"-fA-Na57qVO1"}},{"cell_type":"markdown","source":[],"metadata":{"id":"E8WxzrjErPSd"}},{"cell_type":"code","source":["'''\n","앞서 MLP 클래스에서 정의한 내용에 맞춰서, 밑의 MLP 객체의 파라미터를 수정해주세요. (은닉층 추가 및 노드 개수 수정)\n","num_hidden_1과 num_hidden_2의 노드 개수도 변경 가능합니다! \n","'''\n","model = MLP(num_features=28*28,\n","            num_hidden_1=40,\n","            num_hidden_2=40,\n","            ''' MLP class 정의 내용에 맞춰 수정''',\n","            num_classes=10)\n","\n","model = model.to(DEVICE)\n","\n","'''\n","학습률(lr)과 epoch(NUM_EPOCHS) 지정해주세요. \n","'''\n","optimizer = torch.optim.SGD(model.parameters(), lr='''학습률''') # optimizer는 가중치 업데이트 방법을 바꾸어 성능을 향상 \n","\n","NUM_EPOCHS = 5 # 변경 가능 (10 이상으로 설정하면 학습 시간이 너무 오래 걸릴 수 있습니다.)\n","\n","\n","def compute_accuracy_and_loss(model, data_loader, device):\n","    correct_pred, num_examples = 0, 0\n","    cross_entropy = 0.\n","    for i, (features, targets) in enumerate(data_loader):\n","            \n","        features = features.view(-1, 28*28).to(device)\n","        targets = targets.to(device)\n","\n","        logits, probas = model(features)\n","        \n","        # Loss 계산 시에는 logits 이용\n","        cross_entropy += F.cross_entropy(logits, targets).item()\n","        \n","        # inference 시에는 probas 이용\n","        _, predicted_labels = torch.max(probas, 1)\n","        num_examples += targets.size(0)\n","        correct_pred += (predicted_labels == targets).sum()\n","    return correct_pred.cpu().float()/num_examples * 100, cross_entropy/num_examples\n","    \n","\n","start_time = time.time()\n","train_acc_lst, test_acc_lst = [], []\n","train_loss_lst, test_loss_lst = [], []\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    model.train()\n","    \n","    for batch_idx, (features, targets) in enumerate(train_loader):\n","    \n","        ### PREPARE MINIBATCH\n","        features = features.view(-1, 28*28).to(DEVICE)\n","        targets = targets.to(DEVICE)\n","            \n","        ### FORWARD AND BACK PROP\n","        logits, probas = model(features)\n","        cost = F.cross_entropy(logits, targets)\n","        optimizer.zero_grad()\n","        \n","        cost.backward()\n","        \n","        ### UPDATE MODEL PARAMETERS\n","        optimizer.step()\n","        \n","        ### LOGGING\n","        if not batch_idx % 40:\n","            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n","                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n","                   f' Cost: {cost:.4f}')\n","\n","    model.eval()\n","    with torch.set_grad_enabled(False):\n","        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n","        test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, device=DEVICE)\n","        train_acc_lst.append(train_acc)\n","        test_acc_lst.append(test_acc)\n","        train_loss_lst.append(train_loss)\n","        test_loss_lst.append(test_loss)\n","        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n","              f' | Test Acc.: {test_acc:.2f}%')\n","        \n","    elapsed = (time.time() - start_time)/60\n","    print(f'Time elapsed: {elapsed:.2f} min')\n","  \n","elapsed = (time.time() - start_time)/60\n","print(f'Total Training Time: {elapsed:.2f} min')"],"metadata":{"id":"QLo6cfLcqSVt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. 평가 "],"metadata":{"id":"fcqq6DXusarp"}},{"cell_type":"markdown","source":["테스트 데이터와 학습 데이터의 loss와 Accuracy 변화를 확인해보겠습니다. "],"metadata":{"id":"Aiwp6xY7siTJ"}},{"cell_type":"markdown","source":["Loss"],"metadata":{"id":"Eq6GuR0Xsppn"}},{"cell_type":"code","source":["plt.plot(range(1, NUM_EPOCHS+1), train_loss_lst, label='Training loss')\n","plt.plot(range(1, NUM_EPOCHS+1), test_loss_lst, label='Test loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross entropy')\n","plt.xlabel('Epoch')\n","plt.show()"],"metadata":{"id":"obxFyK5ish7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Accuracy"],"metadata":{"id":"UD__HcXhsrh8"}},{"cell_type":"code","source":["plt.plot(range(1, NUM_EPOCHS+1), train_acc_lst, label='Training accuracy')\n","plt.plot(range(1, NUM_EPOCHS+1), test_acc_lst, label='Test accuracy')\n","plt.legend(loc='upper left')\n","plt.ylabel('Cross entropy')\n","plt.xlabel('Epoch')\n","plt.show()"],"metadata":{"id":"QfRVmMm8sf6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test 정확도"],"metadata":{"id":"bmQ6mM50sxUF"}},{"cell_type":"code","source":["model.eval()\n","with torch.set_grad_enabled(False): # inference 중에 메모리 아끼기 위해 \n","    test_acc, test_loss = compute_accuracy_and_loss(model, test_loader, DEVICE)\n","    print(f'Test accuracy: {test_acc:.2f}%')"],"metadata":{"id":"WtnN5Q5nsyX9"},"execution_count":null,"outputs":[]}]}